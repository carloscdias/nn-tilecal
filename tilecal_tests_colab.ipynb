{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tilecal-tests-colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg_LmIJS2J6Y",
        "colab_type": "text"
      },
      "source": [
        "<h1>Testes com os dados do Tilecal</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUX1I2JrmqQG",
        "colab_type": "text"
      },
      "source": [
        "Clonando repositório para ter acesso aos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssTZWqcLmKT2",
        "colab_type": "code",
        "outputId": "1d7e44d4-0caa-4665-a012-28efb5bb841d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/carloscdias/nn-tilecal.git"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nn-tilecal' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ15-rUfCeuG",
        "colab_type": "text"
      },
      "source": [
        "Leitura dos dados do arquivo texto para um array de arrays em python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aubw_lKpCKsr",
        "colab_type": "code",
        "outputId": "c8bf7cb2-7455-4398-c14a-2ec4ae7baa05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# leitura do arquivo\n",
        "with open('./nn-tilecal/data/pulses_uni0-1024_and_noise_zbEBAch01mu40.txt', 'r') as file:\n",
        "  tilecal_data = [[int(value) for value in line.split()] for line in file.readlines()]\n",
        "\n",
        "print(\"Arquivo contendo {} linhas com {} valores por linha\".format(len(tilecal_data), len(tilecal_data[0])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arquivo contendo 304321 linhas com 8 valores por linha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLJ1hvnceHpu",
        "colab_type": "text"
      },
      "source": [
        "Normalizando e separando dataset entre treino e teste: 70% treino, 30% teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DH0Gw5Mz5M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np_arr = np.array(tilecal_data)\n",
        "X, y = np_arr[:, :7].astype('float32'), np_arr[:, 7].astype('float32')\n",
        "\n",
        "X_scaler = StandardScaler().fit(X)\n",
        "y_scaler = StandardScaler().fit(y.reshape(len(y), 1))\n",
        "X = X_scaler.transform(X)\n",
        "y = y_scaler.transform(y.reshape(len(y), 1))[:,0]\n",
        "\n",
        "# 50% dos dados serão usados para treinamento do modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "# os 50% restantes serão divididos igualmente (25%, 25%)\n",
        "# para serem usados como conjuntos de teste e validação\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR5UNkHPk86g",
        "colab_type": "text"
      },
      "source": [
        "Construindo, treinando e avaliando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psc6e0kE0LGQ",
        "colab_type": "code",
        "outputId": "f15fc970-35b7-41f3-df74-5e5c8634e2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=7))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mse', 'mae', 'mape', 'cosine'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=50, epochs=5,\n",
        "          verbose=1, validation_data=(X_valid, y_valid))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 152160 samples, validate on 76081 samples\n",
            "Epoch 1/5\n",
            "152160/152160 [==============================] - 4s 27us/step - loss: 0.0119 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0715 - mean_absolute_percentage_error: 37.5554 - cosine_proximity: -0.9559 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_mean_absolute_error: 0.0618 - val_mean_absolute_percentage_error: 32.0179 - val_cosine_proximity: -0.9614\n",
            "Epoch 2/5\n",
            "152160/152160 [==============================] - 4s 25us/step - loss: 0.0078 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0610 - mean_absolute_percentage_error: 31.6898 - cosine_proximity: -0.9632 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - val_mean_absolute_error: 0.0607 - val_mean_absolute_percentage_error: 30.8607 - val_cosine_proximity: -0.9635\n",
            "Epoch 3/5\n",
            "152160/152160 [==============================] - 4s 25us/step - loss: 0.0067 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0565 - mean_absolute_percentage_error: 28.8140 - cosine_proximity: -0.9665 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0529 - val_mean_absolute_percentage_error: 27.4965 - val_cosine_proximity: -0.9674\n",
            "Epoch 4/5\n",
            "152160/152160 [==============================] - 4s 25us/step - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0532 - mean_absolute_percentage_error: 27.5350 - cosine_proximity: -0.9681 - val_loss: 0.0053 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0510 - val_mean_absolute_percentage_error: 25.7466 - val_cosine_proximity: -0.9699\n",
            "Epoch 5/5\n",
            "152160/152160 [==============================] - 4s 25us/step - loss: 0.0051 - mean_squared_error: 0.0051 - mean_absolute_error: 0.0499 - mean_absolute_percentage_error: 25.8286 - cosine_proximity: -0.9698 - val_loss: 0.0048 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0475 - val_mean_absolute_percentage_error: 25.0300 - val_cosine_proximity: -0.9705\n",
            "[0.004734921268335339, 0.004734921268335339, 0.04768808345328997, 25.36807166038377, -0.9716088279063267]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faOmfornplaC",
        "colab_type": "text"
      },
      "source": [
        "Criando modelo atual do tilecal (OF2) para fins comparativos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwtB76Yvpjvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "of2_weights = np.array([-0.3781, -0.3572, 0.1808, 0.8125, 0.2767, -0.2056, -0.3292])\n",
        "of2 = lambda x: np.inner(x, of2_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpJiYGlPrSfE",
        "colab_type": "text"
      },
      "source": [
        "Calculando o desvio padrão das distribuições dada por:\n",
        "\n",
        "O_model = A_reco - A_true\n",
        "\n",
        "O_of2 = A_of2 - A_true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA5q6msZslXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c981161-82d9-482f-ca21-5f4c9e0105a5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "A_true = y_test\n",
        "A_reco = model.predict(X_test).reshape(-1)\n",
        "A_of2  = np.array([of2(x) for x in X_test])\n",
        "\n",
        "O_model = A_reco - A_true\n",
        "O_of2   = A_of2 - A_true\n",
        "\n",
        "s_model = pd.Series(O_model.tolist())\n",
        "s_of2   = pd.Series(O_of2.tolist())\n",
        "\n",
        "print(\"Desvio padrão modelo:\", s_model.std())\n",
        "print(\"Desvio padrão OF2:\", s_of2.std())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Desvio padrão modelo: 0.06872537765754318\n",
            "Desvio padrão OF2: 0.7845358097274902\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}